# -*- coding: utf-8 -*-
"""weather_data_collector_dag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hVfZjyS8AbUWnDyAk1qJuwrt7dojJEIh
"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import pendulum
import time
import requests
import pandas as pd
import boto3
from io import StringIO

BASE_URL = "https://api.weather.gov/stations/{station}/observations/latest"
S3_BUCKET_NAME = "mcgillis-wu-beam-smith-mwaa"
S3_DIRECTORY = "weather_data"
WEATHER_STATIONS = ["KORD", "KENW", "KMDW", "KPNT"]

#Define the default args dictionary
default_args = {
    'owner': 'mcgillis-wu-beam-smith',
    'depends_on_past': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

#Function to collect weather data
def weather_data():
    #Ensure data is from today
    collected_data = {}
    now = datetime.utcnow()
    time_of_collection = now.strftime("%Y-%m-%d %H:%M:%S")

    #Iterate through weather stations
    for station in WEATHER_STATIONS:
        url = BASE_URL.format(station=station)
        response = requests.get(url)
        if response.status_code == 200:
            collected_data[station] = response.json()
        else:
            collected_data[station] = {"error": "Failed to fetch data"}
        time.sleep(2)

    records = []
    for station, data in collected_data.items():
        if "properties" not in data:
            continue
        p = data["properties"]
        records.append({
            "timeOfCollection": time_of_collection,
            "timestamp": p.get("timestamp"),
            "station": station,
            "temperature": p.get("temperature", {}).get("value"),
            "dewpoint": p.get("dewpoint", {}).get("value"),
            "windSpeed": p.get("windSpeed", {}).get("value"),
            "barometricPressure": p.get("barometricPressure", {}).get("value"),
            "visibility": p.get("visibility", {}).get("value"),
            "precipitationLastHour": p.get("precipitationLastHour", {}).get("value"),
            "relativeHumidity": p.get("relativeHumidity", {}).get("value"),
            "heatIndex": p.get("heatIndex", {}).get("value"),
        })

    df = pd.DataFrame(records)

    filename = f"{S3_DIRECTORY}/weather_data_{now.strftime('%Y%m%d_%H%M%S')}.csv"

    csv_buffer = StringIO()
    df.to_csv(csv_buffer, index=False)

    s3_client = boto3.client('s3')
    s3_client.put_object(Bucket=S3_BUCKET_NAME, Key=filename, Body=csv_buffer.getvalue())

with DAG(
    dag_id='weather_data_collector_dag',
    default_args=default_args,
    description='Collects weather data from selected stations every 2 hours',
    schedule='0 */2 * * *',
    start_date=pendulum.today('UTC').add(days=-1),
    catchup=False,
    tags=['weather', 'api', 's3'],
) as dag:

    collect_weather_task = PythonOperator(
        task_id='collect_weather_data',
        python_callable=weather_data,
    )